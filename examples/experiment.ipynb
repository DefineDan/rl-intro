{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import asdict\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from rl_intro.agent.core import AgentConfig\n",
    "from rl_intro.agent.agent_expected_sarsa import AgentExpectedSarsa\n",
    "from rl_intro.agent.agent_sarsa import AgentSarsa\n",
    "from rl_intro.agent.agent_q_learning import AgentQLearning\n",
    "from rl_intro.environment.gridworld import GridWorld, GridWorldConfig\n",
    "from rl_intro.agent.policy import EpsilonGreedyPolicy, EpsilonGreedyConfig\n",
    "from rl_intro.simulation.experiment import (\n",
    "    ExperimentBatch,\n",
    "    ExperimentConfig,\n",
    "    AgentRecipe,\n",
    "    EnvironmentRecipe,\n",
    ")\n",
    "from rl_intro.evaluation.parse import parse_experiment_json, parse_experiment_batch_json\n",
    "from rl_intro.evaluation.analyze import analyze_experiment, analyze_experiments\n",
    "from rl_intro.evaluation.plot import (\n",
    "    plot_state_visit_frequency,\n",
    "    plot_final_values,\n",
    "    plot_cumulative_reward,\n",
    "    plot_average_reward_per_episode,\n",
    ")\n",
    "from rl_intro.utils.logger import logger\n",
    "from rl_intro.utils.visualize import grid_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee50472",
   "metadata": {},
   "source": [
    "## Single experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664207c1",
   "metadata": {},
   "source": [
    "### Running the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b847b",
   "metadata": {},
   "source": [
    "Configuration of the environment, agent and experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c47eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = 4, 10\n",
    "n_actions = 4\n",
    "\n",
    "experiment_config = ExperimentConfig(n_episodes=1000, max_steps=200)\n",
    "\n",
    "env_config = GridWorldConfig(\n",
    "    width=n_cols,\n",
    "    height=n_rows,\n",
    "    start_states=[0],\n",
    "    terminal_states=[39],\n",
    "    cliff_states=[4, 24, 5, 25],\n",
    "    wall_states=[2, 12, 22, 17, 27, 37],\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "agent_config = AgentConfig(\n",
    "    n_states=n_cols * n_rows,\n",
    "    n_actions=n_actions,\n",
    "    random_seed=42,\n",
    "    learning_rate=0.3,\n",
    "    discount=1.0,\n",
    ")\n",
    "policy_config = EpsilonGreedyConfig(epsilon=0.1)\n",
    "\n",
    "logger.setLevel(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea8f89b",
   "metadata": {},
   "source": [
    "Running an experiment with given configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21e59c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentExpectedSarsa(agent_config, EpsilonGreedyPolicy(policy_config))\n",
    "env = GridWorld(env_config)\n",
    "experiment = Experiment(agent, env, experiment_config)\n",
    "\n",
    "logger.info(f\"Environment: {env.to_str()}\")\n",
    "logger.info(f\"Agent: {agent}\")\n",
    "\n",
    "# * running the experiment\n",
    "experiment_log = experiment.run()\n",
    "\n",
    "# * log extra information like this\n",
    "logger.debug(grid_str(agent.get_greedy_actions(), n_cols, n_rows))\n",
    "logger.debug(grid_str(agent.get_greedy_values(), n_cols, n_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa303c2",
   "metadata": {},
   "source": [
    "Saving experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a6d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = Path(\"../data\") / \"single_experiment_logs.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(log_file, \"w\") as f:\n",
    "    json.dump(asdict(experiment_log), f, indent=4)\n",
    "logger.info(f\"Experiment completed and logs saved to '{log_file}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b976afe5",
   "metadata": {},
   "source": [
    "### Analyzing the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dec618",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_log = parse_experiment_json(log_file) \n",
    "experiment_analysis = analyze_experiment(experiment_log, n_rows, n_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1741a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cumulative_reward([experiment_analysis], plt.subplots()[1], interval=(0, 5000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599f827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_reward_per_episode([\n",
    "    experiment_analysis], plt.subplots()[1], interval=(0, 300)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246fc1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax = ax.flatten()\n",
    "plot_final_values(experiment_analysis, ax[0])\n",
    "plot_state_visit_frequency(experiment_analysis, ax[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f500562e",
   "metadata": {},
   "source": [
    "## Multi experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020c2c6a",
   "metadata": {},
   "source": [
    "### Running the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a342b7",
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "n_rows, n_cols = 4, 10\n",
    "n_actions = 4\n",
    "\n",
    "experiment_config = ExperimentConfig(n_episodes=1000, max_steps=200)\n",
    "\n",
    "env_config = GridWorldConfig(\n",
    "    width=n_cols,\n",
    "    height=n_rows,\n",
    "    start_states=[0],\n",
    "    terminal_states=[39],\n",
    "    cliff_states=[4, 24, 5, 25],\n",
    "    wall_states=[2, 12, 22, 17, 27, 37],\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "agent_config = AgentConfig(\n",
    "    n_states=n_cols * n_rows,\n",
    "    n_actions=n_actions,\n",
    "    random_seed=42,\n",
    "    learning_rate=0.3,\n",
    "    discount=1.0,\n",
    ")\n",
    "policy_config = EpsilonGreedyConfig(epsilon=0.1)\n",
    "\n",
    "logger.setLevel(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb617f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_recipe = EnvironmentRecipe(\n",
    "    environment_class=GridWorld,\n",
    "    environment_config=env_config,\n",
    ")\n",
    "\n",
    "agent_sarsa_recipe = AgentRecipe(\n",
    "    agent_class=AgentSarsa,\n",
    "    agent_config=agent_config,\n",
    "    policy_class=EpsilonGreedyPolicy,\n",
    "    policy_config=policy_config,\n",
    ")\n",
    "\n",
    "agent_expected_sarsa_recipe = AgentRecipe(\n",
    "    agent_class=AgentExpectedSarsa,\n",
    "    agent_config=agent_config,\n",
    "    policy_class=EpsilonGreedyPolicy,\n",
    "    policy_config=policy_config,\n",
    ")\n",
    "\n",
    "agent_q_learning_recipe = AgentRecipe(\n",
    "    agent_class=AgentQLearning,\n",
    "    agent_config=agent_config,\n",
    "    policy_class=EpsilonGreedyPolicy,\n",
    "    policy_config=policy_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e02ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_batch = ExperimentBatch(\n",
    "    agent_recipes=[\n",
    "        agent_sarsa_recipe,\n",
    "        agent_expected_sarsa_recipe,\n",
    "        agent_q_learning_recipe,\n",
    "    ],\n",
    "    env_recipes=[environment_recipe],\n",
    "    experiment_config=experiment_config,\n",
    "    n_runs=10,\n",
    ")\n",
    "\n",
    "# * running the experiment\n",
    "experiment_logs = experiment_batch.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e50196",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = Path(\"../data\") / \"single_experiment_logs.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(log_file, \"w\") as f:\n",
    "    json.dump([asdict(log) for log in experiment_logs], f, indent=4)\n",
    "logger.info(f\"Experiment completed and logs saved to '{log_file}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ae6a02",
   "metadata": {},
   "source": [
    "### Analyzing the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc2d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_logs = parse_experiment_batch_json(log_file)\n",
    "experiment_results = analyze_experiments(\n",
    "    experiment_logs, n_rows, n_cols, agent_grouping=True\n",
    ")\n",
    "\n",
    "n_results = len(experiment_results)  # seeds for each agent are grouped together\n",
    "logger.info(f\"Grouped analysis into {n_results} result(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855368b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_cumulative_reward(experiment_results, plt.subplots()[1], interval=(0, 20000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d32e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_reward_per_episode(\n",
    "    experiment_results, plt.subplots()[1], interval=(0, 500)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8264789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, experiment_analysis in enumerate(experiment_results):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax = ax.flatten()\n",
    "    plot_final_values(experiment_analysis, ax[0])\n",
    "    plot_state_visit_frequency(experiment_analysis, ax[1]);\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
